{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distracted Driver Detection\n",
    "\n",
    "Attempting to finetune Resnet model to solve https://www.kaggle.com/c/state-farm-distracted-driver-detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './../..')\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "# base_dir = '../sample/'\n",
    "base_dir = '../'\n",
    "batch_size = 64\n",
    "output_size = 10\n",
    "dropout = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17850 images belonging to 10 classes.\n",
      "Found 17850 images belonging to 10 classes.\n",
      "Found 4574 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "gen_with_aug = image.ImageDataGenerator(rotation_range=15, \n",
    "                                        height_shift_range=0.05, \n",
    "                                        shear_range=0.1, \n",
    "                                        channel_shift_range=20, \n",
    "                                        width_shift_range=0.1)\n",
    "\n",
    "batches = gen.flow_from_directory(base_dir + 'train/', \n",
    "                                  target_size=(224,224),\n",
    "                                  class_mode='categorical', \n",
    "                                  shuffle=False, \n",
    "                                  batch_size=batch_size)\n",
    "batches_aug = gen_with_aug.flow_from_directory(base_dir + 'train/', \n",
    "                                                   target_size=(224,224),\n",
    "                                                   class_mode='categorical', \n",
    "                                                   shuffle=True, \n",
    "                                                   batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(base_dir + 'valid/',\n",
    "                                     target_size=(224,224),\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=False,\n",
    "                                     batch_size=batch_size)\n",
    "test_batches = gen.flow_from_directory(base_dir + 'test/',\n",
    "                                     target_size=(224,224),\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=False,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "# Fragmented test batches for pseudo labeling\n",
    "# test_batches_arr = []\n",
    "# for i in range(4):\n",
    "#     b = gen.flow_from_directory(base_dir + 'test' + str(i+1) + '/',\n",
    "#                                      target_size=(224,224),\n",
    "#                                      class_mode='categorical',\n",
    "#                                      shuffle=False,\n",
    "#                                      batch_size=batch_size)\n",
    "#     test_batches_arr.append(b)\n",
    "\n",
    "trn_labels = to_categorical(batches.classes)\n",
    "val_labels = to_categorical(val_batches.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional pre-computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = Resnet50((224,224), False).model # convolutional layers\n",
    "\n",
    "batches.reset()\n",
    "trn_features = cm.predict_generator(batches, steps(batches, batch_size), verbose=1)\n",
    "save_array(base_dir + 'models/resnet_train_convlayer_features.bc', trn_features)\n",
    "\n",
    "val_batches.reset()\n",
    "val_features = cm.predict_generator(val_batches, steps(val_batches, batch_size), verbose=1)\n",
    "save_array(base_dir + 'models/resnet_valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    b = test_batches_arr[i]\n",
    "    b.reset()\n",
    "    features = cm.predict_generator(b, steps(b, batch_size), verbose=1)\n",
    "    save_array(base_dir + 'models/resnet_test' + str(i + 1) + '_convlayer_features.bc', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(base_dir + 'models/resnet_train_convlayer_features.bc')\n",
    "val_features = load_array(base_dir + 'models/resnet_valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_dense_layers(model, index):\n",
    "    dm = resnet_fc_model(model, output_size, dropout=dropout)\n",
    "    for l in dm.layers: l.trainable = True\n",
    "    \n",
    "    fit_with_features(dm, RMSprop(1e-3), 16, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-4), 14, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-5), 12, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-6), 10, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-7), 8, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    \n",
    "    for i in range(6): model.layers[-6 + i].set_weights(dm.layers[i+1].get_weights())\n",
    "    model.save_weights(base_dir + 'models/resnet_last' + str(index) + '.h5')\n",
    "    \n",
    "def finetune_w_valid_pseudo_labels(model, index):\n",
    "    finetune_w_pseudo_labels(model, index, val_features, \"resnet_pseudo_label\")  \n",
    "    \n",
    "def finetune_w_test_pseudo_labels(model, index):\n",
    "    for i in range(4):\n",
    "        features = load_array(base_dir + 'models/resnet_test' + str(i+1) + '_convlayer_features.bc')\n",
    "        finetune_w_pseudo_labels(model, index, features, \"resnet_pseudo_label_w_test\")\n",
    "        \n",
    "def finetune_w_pseudo_labels(model, index, features, log_id):\n",
    "    dm = resnet_fc_model(model, output_size, dropout=dropout)\n",
    "    for l in dm.layers: l.trainable = True\n",
    "        \n",
    "    pseudo_labels = dm.predict(features, batch_size=batch_size, verbose=1)\n",
    "    comb_labels = np.concatenate([trn_labels, pseudo_labels])\n",
    "    comb_features = np.concatenate([trn_features, features])\n",
    "\n",
    "    fit_with_features(dm, RMSprop(1e-5), 10, comb_features, comb_labels, val_features, val_labels, batch_size=batch_size) #10\n",
    "    fit_with_features(dm, RMSprop(1e-6), 8, comb_features, comb_labels, val_features, val_labels, batch_size=batch_size) #8\n",
    "    fit_with_features(dm, RMSprop(1e-7), 6, comb_features, comb_labels, val_features, val_labels, batch_size=batch_size) #6\n",
    "\n",
    "    for i in range(6): model.layers[-6 + i].set_weights(dm.layers[i+1].get_weights())\n",
    "    model.save_weights(base_dir + 'models/' + log_id + str(index) + '.h5')\n",
    "    \n",
    "def finetune_dense_layers_with_aug(model, index):\n",
    "    for i in range(len(model.layers)): model.layers[i].trainable = i >= len(model.layers) - 6\n",
    "    fit_with_batches(model, RMSprop(1e-3), 5, batches_aug, val_batches, batch_size=batch_size)\n",
    "    fit_with_batches(model, RMSprop(1e-4), 4, batches_aug, val_batches, batch_size=batch_size)\n",
    "    fit_with_batches(model, RMSprop(1e-5), 3, batches_aug, val_batches, batch_size=batch_size)\n",
    "    fit_with_batches(model, RMSprop(1e-6), 2, batches_aug, val_batches, batch_size=batch_size)\n",
    "    fit_with_batches(model, RMSprop(1e-7), 1, batches_aug, val_batches, batch_size=batch_size)\n",
    "    model.save_weights(base_dir + 'models/resnet_dense_pseudo_aug' + str(index) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "186/279 [===================>..........] - ETA: 97s - loss: 2.2256 - acc: 0.6268"
     ]
    }
   ],
   "source": [
    "# model = resnet(output_size, dropout=dropout)\n",
    "# finetune_dense_layers(model, 1)\n",
    "# finetune_w_valid_pseudo_labels(model, 1)\n",
    "# finetune_w_test_pseudo_labels(model, 1)\n",
    "finetune_dense_layers_with_aug(model, 1)\n",
    "log_action(\"Finished training model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = resnet(output_size)\n",
    "model.load_weights(base_dir + 'models/resnet_dense_pseudo_aug0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)\n",
    "\n",
    "preds = model.predict_generator(test_batches, steps(test_batches, batch_size), verbose=1)\n",
    "clipped_preds = do_clip(preds, 0.93)\n",
    "\n",
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "submission = pd.DataFrame(clipped_preds, columns=classes)\n",
    "submission.insert(0, 'img', [a[8:] for a in test_batches.filenames])\n",
    "file_path = base_dir + 'submission.gz'\n",
    "submission.to_csv(file_path, index=False, compression='gzip')\n",
    "    \n",
    "from IPython.display import FileLink\n",
    "FileLink(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../submission.gz' target='_blank'>../submission.gz</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/fast/kaggle/farmer/submission.gz"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Not tried\n",
    "\n",
    "- Other architecture\n",
    "- Ensembling"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
