{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './../..')\n",
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "batch_size=64\n",
    "output_size = 2\n",
    "#base_dir = '../\n",
    "base_dir = '../sample/'\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "gen_with_aug = image.ImageDataGenerator(rotation_range=10, \n",
    "                                        width_shift_range=0.05, \n",
    "                                        zoom_range=0.05, \n",
    "                                        channel_shift_range=10, \n",
    "                                        height_shift_range=0.05, \n",
    "                                        shear_range=0.05, \n",
    "                                        horizontal_flip=True)\n",
    "\n",
    "batches = gen.flow_from_directory(base_dir + 'train/', \n",
    "                                  target_size=(224,224),\n",
    "                                  class_mode='categorical', \n",
    "                                  shuffle=False, \n",
    "                                  batch_size=batch_size)\n",
    "batches_aug = gen_with_aug.flow_from_directory(base_dir + 'train/', \n",
    "                                                   target_size=(224,224),\n",
    "                                                   class_mode='categorical', \n",
    "                                                   shuffle=True, \n",
    "                                                   batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(base_dir + 'valid/',\n",
    "                                     target_size=(224,224),\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=False,\n",
    "                                     batch_size=batch_size)\n",
    "test_batches = gen.flow_from_directory(base_dir + 'test/',\n",
    "                                     target_size=(224,224),\n",
    "                                     class_mode='categorical',\n",
    "                                     shuffle=False,\n",
    "                                     batch_size=batch_size*2)\n",
    "\n",
    "trn_labels = to_categorical(batches.classes)\n",
    "val_labels = to_categorical(val_batches.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_last_layer(model, index):\n",
    "    log_action(\"Training last layer\")\n",
    "    dm = vgg_fc_model(model, output_size, dropout=0.5)\n",
    "    for i in range(len(dm.layers)): dm.layers[i].trainable = i >= len(dm.layers) - 3\n",
    "    \n",
    "    fit_with_features(dm, RMSprop(1e-5), 12, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-7), 6, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    \n",
    "    for l1,l2 in zip(model.layers[last_conv_idx(model) + 1:], dm.layers): l1.set_weights(l2.get_weights())\n",
    "    model.save_weights(base_dir + 'models/last' + str(index) + '.h5')\n",
    "    \n",
    "def finetune_dense_layers(model, index):\n",
    "    log_action(\"Training dense layers\")\n",
    "    dm = vgg_fc_model(model, output_size, dropout=0.5)\n",
    "    for l in dm.layers: l.trainable = True\n",
    "    \n",
    "    fit_with_features(dm, RMSprop(1e-5), 10, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-6), 8, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    fit_with_features(dm, RMSprop(1e-7), 10, trn_features, trn_labels, val_features, val_labels, batch_size=batch_size)\n",
    "    \n",
    "    for l1,l2 in zip(model.layers[last_conv_idx(model) + 1:], dm.layers): l1.set_weights(l2.get_weights())\n",
    "    model.save_weights(base_dir + 'models/dense' + str(index) + '.h5')\n",
    "    \n",
    "def finetune_dense_layers_with_aug(model, index):\n",
    "    log_action(\"Training dense layers with augmentations\")\n",
    "    for i in range(len(model.layers)): model.layers[i].trainable = i >= 16\n",
    "    fit_dense_layers_with_aug(model, index, RMSprop(1e-5), 8)\n",
    "    fit_dense_layers_with_aug(model, index, RMSprop(1e-7), 10)\n",
    "    \n",
    "def fit_dense_layers_with_aug(model, index, lr, epochs):\n",
    "    fit_with_batches(model, lr, epochs, batches_aug, val_batches, batch_size=batch_size)\n",
    "    model.save_weights(base_dir + 'models/dense_aug' + str(index) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache convolutional output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = conv_model(vgg(output_size, dropout=dropout))\n",
    "\n",
    "batches.reset()\n",
    "trn_features = conv_model.predict_generator(batches, steps(batches, batch_size))\n",
    "save_array(base_dir + 'models/train_convlayer_features.bc', trn_features)\n",
    "\n",
    "val_batches.reset()\n",
    "val_features = conv_model.predict_generator(val_batches, steps(batches, batch_size))\n",
    "save_array(base_dir + 'models/valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(base_dir + 'models/train_convlayer_features.bc')\n",
    "val_features = load_array(base_dir + 'models/valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logs()\n",
    "for i in range(5):\n",
    "    model = vgg(output_size, dropout=dropout)\n",
    "    finetune_last_layer(model, i)\n",
    "    finetune_dense_layers(model, i)\n",
    "    finetune_dense_layers_with_aug(model, i)\n",
    "log_action(\"finished training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens_preds = ensemble_predict(vgg(output_size, dropout=dropout), 'models/dense_aug', val_batches, size=5)\n",
    "print(categorical_accuracy(val_labels, ens_preds).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "preds = ensemble_predict(vgg(output_size, dropout=dropout), 'models/dense_aug', test_batches, size=5)\n",
    "\n",
    "# Clip predictions\n",
    "isdog = preds[:,1].clip(min=0.020, max=0.980) \n",
    "\n",
    "# Extract image ids\n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[6:f.find('.')]) for f in filenames])\n",
    "\n",
    "# Write to CSV file\n",
    "subm = np.stack([ids,isdog], axis=1)\n",
    "np.savetxt('../sample_submission.csv', subm, fmt='%d,%.5f', header='id,label', comments='')\n",
    "\n",
    "# Get link\n",
    "from IPython.display import FileLink\n",
    "FileLink('../sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
